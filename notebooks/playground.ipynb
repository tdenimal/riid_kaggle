{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1602868649003",
   "display_name": "Python 3.7.9 64-bit ('riid_kaggle': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Should include a call to GCP Big query#\n",
    "#Install gsutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'context' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-321c6c4e9614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Load raw datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mquestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"questions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlectures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lectures\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#train =  context.catalog.load(\"train_filter\",)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'context' is not defined"
     ]
    }
   ],
   "source": [
    "#Load raw datasets\n",
    "questions = context.catalog.load(\"questions\",) \n",
    "lectures = context.catalog.load(\"lectures\",)\n",
    "#train =  context.catalog.load(\"train_filter\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.content_type_id == False]\n",
    "#arrange by timestamp\n",
    "\n",
    "\n",
    "train = train.sort_values(['timestamp'], ascending=True)\n",
    "\n",
    "train.drop(['timestamp','content_type_id'], axis=1,   inplace=True)\n",
    "\n",
    "results_c = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\n",
    "results_c.columns = [\"answered_correctly_content\"]\n",
    "\n",
    "results_u = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum'])\n",
    "results_u.columns = [\"answered_correctly_user\", 'sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in question df\n",
    "questions_df = pd.read_csv('data/01_raw/questions.csv',\n",
    "                            usecols=[0,1, 3,4],\n",
    "                            dtype={'question_id': 'int16',\n",
    "                                   'part': 'int8',\n",
    "                                   'bundle_id': 'int8',\n",
    "                                   'tags': 'str'}\n",
    "                                  )\n",
    "\n",
    "tag = questions_df[\"tags\"].str.split(\" \", n = 10, expand = True) \n",
    "tag.columns = ['tags1','tags2','tags3','tags4','tags5','tags6']\n",
    "\n",
    "questions_df =  pd.concat([questions_df,tag],axis=1)\n",
    "questions_df['tags1'] = pd.to_numeric(questions_df['tags1'], errors='coerce')\n",
    "questions_df['tags2'] = pd.to_numeric(questions_df['tags2'], errors='coerce')\n",
    "questions_df['tags3'] = pd.to_numeric(questions_df['tags3'], errors='coerce')\n",
    "questions_df['tags4'] = pd.to_numeric(questions_df['tags4'], errors='coerce')\n",
    "questions_df['tags5'] = pd.to_numeric(questions_df['tags5'], errors='coerce')\n",
    "questions_df['tags6'] = pd.to_numeric(questions_df['tags6'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[80000000:,:]\n",
    "X['prior_question_had_explanation'].fillna(False, inplace=True)\n",
    "X = pd.merge(X, results_u, on=['user_id'], how=\"left\")\n",
    "X = pd.merge(X, results_c, on=['content_id'], how=\"left\")\n",
    "X = pd.merge(X, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
    "\n",
    "X=X[X.answered_correctly!= -1 ]\n",
    "X=X.sort_values(['user_id'])\n",
    "Y = X[[\"answered_correctly\"]]\n",
    "X = X.drop([\"answered_correctly\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         user_id  content_id  prior_question_elapsed_time  \\\n2969848    13134       12263                      10000.0   \n4342675    13134       12115                      19000.0   \n4342647    13134       12257                      22000.0   \n4342609    13134       12236                      18000.0   \n5217369    13134       13063                      29666.0   \n\n         prior_question_had_explanation  answered_correctly_user    sum  \\\n2969848                            True                 0.706356  878.0   \n4342675                            True                 0.706356  878.0   \n4342647                            True                 0.706356  878.0   \n4342609                            True                 0.706356  878.0   \n5217369                            True                 0.706356  878.0   \n\n         answered_correctly_content  question_id  bundle_id  part  \\\n2969848                    0.570648        12263        -25     2   \n4342675                    0.809202        12115         83     2   \n4342647                    0.820975        12257        -31     2   \n4342609                    0.720157        12236        -52     2   \n5217369                    0.960396        13063          5     4   \n\n                  tags  tags1  tags2  tags3  tags4  tags5  tags6  \\\n2969848   138 41 81 92  138.0   41.0   81.0   92.0    NaN    NaN   \n4342675  143 140 38 81  143.0  140.0   38.0   81.0    NaN    NaN   \n4342647   90 100 92 29   90.0  100.0   92.0   29.0    NaN    NaN   \n4342609  155 163 92 29  155.0  163.0   92.0   29.0    NaN    NaN   \n5217369     136 103 81  136.0  103.0   81.0    NaN    NaN    NaN   \n\n         prior_question_had_explanation_enc  \n2969848                                   1  \n4342675                                   1  \n4342647                                   1  \n4342609                                   1  \n5217369                                   1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>content_id</th>\n      <th>prior_question_elapsed_time</th>\n      <th>prior_question_had_explanation</th>\n      <th>answered_correctly_user</th>\n      <th>sum</th>\n      <th>answered_correctly_content</th>\n      <th>question_id</th>\n      <th>bundle_id</th>\n      <th>part</th>\n      <th>tags</th>\n      <th>tags1</th>\n      <th>tags2</th>\n      <th>tags3</th>\n      <th>tags4</th>\n      <th>tags5</th>\n      <th>tags6</th>\n      <th>prior_question_had_explanation_enc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2969848</th>\n      <td>13134</td>\n      <td>12263</td>\n      <td>10000.0</td>\n      <td>True</td>\n      <td>0.706356</td>\n      <td>878.0</td>\n      <td>0.570648</td>\n      <td>12263</td>\n      <td>-25</td>\n      <td>2</td>\n      <td>138 41 81 92</td>\n      <td>138.0</td>\n      <td>41.0</td>\n      <td>81.0</td>\n      <td>92.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4342675</th>\n      <td>13134</td>\n      <td>12115</td>\n      <td>19000.0</td>\n      <td>True</td>\n      <td>0.706356</td>\n      <td>878.0</td>\n      <td>0.809202</td>\n      <td>12115</td>\n      <td>83</td>\n      <td>2</td>\n      <td>143 140 38 81</td>\n      <td>143.0</td>\n      <td>140.0</td>\n      <td>38.0</td>\n      <td>81.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4342647</th>\n      <td>13134</td>\n      <td>12257</td>\n      <td>22000.0</td>\n      <td>True</td>\n      <td>0.706356</td>\n      <td>878.0</td>\n      <td>0.820975</td>\n      <td>12257</td>\n      <td>-31</td>\n      <td>2</td>\n      <td>90 100 92 29</td>\n      <td>90.0</td>\n      <td>100.0</td>\n      <td>92.0</td>\n      <td>29.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4342609</th>\n      <td>13134</td>\n      <td>12236</td>\n      <td>18000.0</td>\n      <td>True</td>\n      <td>0.706356</td>\n      <td>878.0</td>\n      <td>0.720157</td>\n      <td>12236</td>\n      <td>-52</td>\n      <td>2</td>\n      <td>155 163 92 29</td>\n      <td>155.0</td>\n      <td>163.0</td>\n      <td>92.0</td>\n      <td>29.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5217369</th>\n      <td>13134</td>\n      <td>13063</td>\n      <td>29666.0</td>\n      <td>True</td>\n      <td>0.706356</td>\n      <td>878.0</td>\n      <td>0.960396</td>\n      <td>13063</td>\n      <td>5</td>\n      <td>4</td>\n      <td>136 103 81</td>\n      <td>136.0</td>\n      <td>103.0</td>\n      <td>81.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb_make = LabelEncoder()\n",
    "X[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(X[\"prior_question_had_explanation\"])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[['answered_correctly_user', 'answered_correctly_content', 'sum','bundle_id','part','prior_question_elapsed_time','prior_question_had_explanation_enc','tags1','tags2','tags3']] \n",
    "\n",
    "X.fillna(0.5,  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = lgb.Dataset(X, Y,categorical_feature = ['part','tags1','tags2','tags3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115872 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091193 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "\n",
    "model_cv = lgb.cv(parameters,\n",
    "                       train_ds,\n",
    "                       nfold=10,\n",
    "                       stratified=True,\n",
    "                       num_boost_round=5000,\n",
    "                       early_stopping_rounds=100,\n",
    "                       return_cvbooster=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/home/tdenimal/miniconda3/envs/riid_kaggle/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-31c8b5bc0592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Plot metric mean value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auc mean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auc-mean\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#Plot metric mean value\n",
    "plt.title(\"auc mean\")\n",
    "plt.plot(model_cv[\"auc-mean\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-be6b81feaac7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Plot metric mean value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auc std\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auc-std\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#Plot metric mean value\n",
    "plt.title(\"auc std\")\n",
    "plt.plot(model_cv[\"auc-std\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "from  sklearn.model_selection import train_test_split\n",
    "Xt, Xv, Yt, Yv = train_test_split(X, Y, test_size =0.2, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lgb_train = lgb.Dataset(Xt, Yt,categorical_feature = ['part','tags1','tags2','tags3'])\n",
    "lgb_eval = lgb.Dataset(Xv, Yv, reference=lgb_train,categorical_feature = ['part','tags1','tags2','tags3'])\n",
    "\n",
    "model = lgb.train(\n",
    "    params, lgb_train,\n",
    "    valid_sets=[lgb_train, lgb_eval],\n",
    "    verbose_eval=10,\n",
    "    num_boost_round=10000,\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  }
 ]
}