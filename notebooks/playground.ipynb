{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1603572149477",
   "display_name": "Python 3.7.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Should include a call to GCP Big query#\n",
    "#Install gsutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load raw datasets\n",
    "#questions = context.catalog.load(\"questions\",) \n",
    "#lectures = context.catalog.load(\"lectures\",)\n",
    "#train =  context.catalog.load(\"train_filter\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train[train.content_type_id == False]\n",
    "# #arrange by timestamp\n",
    "\n",
    "##\n",
    "# train = train.sort_values(['timestamp'], ascending=True)\n",
    "\n",
    "# train.drop(['timestamp','content_type_id'], axis=1,   inplace=True)\n",
    "\n",
    "# results_c = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\n",
    "# results_c.columns = [\"answered_correctly_content\"]\n",
    "\n",
    "# results_u = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum'])\n",
    "# results_u.columns = [\"answered_correctly_user\", 'sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in question df\n",
    "# questions_df = pd.read_csv('data/01_raw/questions.csv',\n",
    "#                             usecols=[0,1, 3,4],\n",
    "#                             dtype={'question_id': 'int16',\n",
    "#                                    'part': 'int8',\n",
    "#                                    'bundle_id': 'int8',\n",
    "#                                    'tags': 'str'}\n",
    "#                                   )\n",
    "\n",
    "# tag = questions_df[\"tags\"].str.split(\" \", n = 10, expand = True) \n",
    "# tag.columns = ['tags1','tags2','tags3','tags4','tags5','tags6']\n",
    "\n",
    "# questions_df =  pd.concat([questions_df,tag],axis=1)\n",
    "# questions_df['tags1'] = pd.to_numeric(questions_df['tags1'], errors='coerce')\n",
    "# questions_df['tags2'] = pd.to_numeric(questions_df['tags2'], errors='coerce')\n",
    "# questions_df['tags3'] = pd.to_numeric(questions_df['tags3'], errors='coerce')\n",
    "# questions_df['tags4'] = pd.to_numeric(questions_df['tags4'], errors='coerce')\n",
    "# questions_df['tags5'] = pd.to_numeric(questions_df['tags5'], errors='coerce')\n",
    "# questions_df['tags6'] = pd.to_numeric(questions_df['tags6'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = train.iloc[85000000:,:]\n",
    "#X['prior_question_had_explanation'].fillna(False, inplace=True)\n",
    "# X = pd.merge(X, results_u, on=['user_id'], how=\"left\")\n",
    "# X = pd.merge(X, results_c, on=['content_id'], how=\"left\")\n",
    "# X = pd.merge(X, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
    "\n",
    "# X=X[X.answered_correctly!= -1 ]\n",
    "#X=X.sort_values(['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import json\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iteration :0\n[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n[LightGBM] [Info] Number of positive: 2889059, number of negative: 2363068\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.178014 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2487\n[LightGBM] [Info] Number of data points in the train set: 5252127, number of used features: 21\n[LightGBM] [Info] Number of positive: 2889059, number of negative: 2363068\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.153409 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2487\n[LightGBM] [Info] Number of data points in the train set: 5252127, number of used features: 21\n[LightGBM] [Info] Number of positive: 2889059, number of negative: 2363068\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141630 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2487\n[LightGBM] [Info] Number of data points in the train set: 5252127, number of used features: 21\n[LightGBM] [Info] Number of positive: 2889059, number of negative: 2363068\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.161403 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2487\n[LightGBM] [Info] Number of data points in the train set: 5252127, number of used features: 21\n[LightGBM] [Info] Number of positive: 2889060, number of negative: 2363068\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.150068 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2487\n[LightGBM] [Info] Number of data points in the train set: 5252128, number of used features: 21\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550074 -> initscore=0.200970\n[LightGBM] [Info] Start training from score 0.200970\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550074 -> initscore=0.200970\n[LightGBM] [Info] Start training from score 0.200970\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550074 -> initscore=0.200970\n[LightGBM] [Info] Start training from score 0.200970\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550074 -> initscore=0.200970\n[LightGBM] [Info] Start training from score 0.200970\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.550074 -> initscore=0.200970\n[LightGBM] [Info] Start training from score 0.200970\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-65606bdd9c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m                         \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                         return_cvbooster=True)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/riid_kaggle/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric, return_cvbooster)\u001b[0m\n\u001b[1;32m    590\u001b[0m                                     \u001b[0mend_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_agg_cv_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_train_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/riid_kaggle/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mhandler_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboosters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandler_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/riid_kaggle/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2370\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   2371\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2372\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   2373\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2374\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for it,y in enumerate(range(0,78,8)):\n",
    "\n",
    "    if y == 72:\n",
    "        end_range = 78\n",
    "    else:\n",
    "        end_range=y+8\n",
    "\n",
    "    print(f\"Iteration :{it}\")\n",
    "    list_df = []\n",
    "    for x in range(y,end_range):\n",
    "        list_df +=  [pd.read_csv(\"../data/01_raw/feat_tab0000000000\"+f\"{x:02d}\")]\n",
    "    train = pd.concat(list_df)\n",
    "    del list_df\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    Y = train[[\"answered_correctly\"]]\n",
    "    train = train.drop([\"answered_correctly\"], axis=1)\n",
    "\n",
    "\n",
    "    lb_make = LabelEncoder()\n",
    "    train[\"section\"] = lb_make.fit_transform(train[\"section\"])\n",
    "\n",
    "    train = train[[col for col in train.columns if col not in ['user_id',\"timestamp\"]]]\n",
    "    train.fillna(-1,inplace=True)\n",
    "    train_ds = lgb.Dataset(train, Y,categorical_feature = ['section','part','tags1','tags2','tags3','profile'])\n",
    "\n",
    "    del train,Y\n",
    "    gc.collect()\n",
    "\n",
    "    if it == 0:\n",
    "        model_cv = lgb.cv(parameters,\n",
    "                        train_ds,\n",
    "                        nfold=5,\n",
    "                        stratified=True,\n",
    "                        num_boost_round=5000,\n",
    "                        early_stopping_rounds=100,\n",
    "                        return_cvbooster=True)\n",
    "\n",
    "    else:\n",
    "        model_cv = lgb.cv(parameters,\n",
    "                        train_ds,\n",
    "                        nfold=5,\n",
    "                        stratified=True,\n",
    "                        num_boost_round=5000,\n",
    "                        early_stopping_rounds=100,\n",
    "                        return_cvbooster=True,\n",
    "                        init_model=lgb.Booster(model_file=\"model_\"+str(it-1)+\".bin\"))\n",
    "\n",
    "    with open('auc_mean_'+str(it)+'.json', 'w') as f:\n",
    "        f.write(json.dumps(model_cv[\"auc-mean\"]))\n",
    "    with open('auc_stdv_'+str(it)+'.json', 'w') as f:\n",
    "        f.write(json.dumps(model_cv[\"auc-stdv\"]))\n",
    "    \n",
    "    model_cv[\"cvbooster\"].boosters[4].save_model(\"model_\"+str(it)+\".bin\")\n",
    "\n",
    "    del train_ds, model_cv\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[['answered_correctly_user', 'answered_correctly_content', 'sum','bundle_id','part','prior_question_elapsed_time','prior_question_had_explanation_enc','tags1','tags2','tags3']] \n",
    "\n",
    "# X.fillna(0.5,  inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "from  sklearn.model_selection import train_test_split\n",
    "Xt, Xv, Yt, Yv = train_test_split(X, Y, test_size =0.2, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lgb_train = lgb.Dataset(Xt, Yt,categorical_feature = ['part','tags1','tags2','tags3'])\n",
    "lgb_eval = lgb.Dataset(Xv, Yv, reference=lgb_train,categorical_feature = ['part','tags1','tags2','tags3'])\n",
    "\n",
    "model = lgb.train(\n",
    "    params, lgb_train,\n",
    "    valid_sets=[lgb_train, lgb_eval],\n",
    "    verbose_eval=10,\n",
    "    num_boost_round=10000,\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  }
 ]
}